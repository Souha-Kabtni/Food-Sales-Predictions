{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gxTHivvtJ-6VkO440qDzCBAeSAPgMKu4",
      "authorship_tag": "ABX9TyPk6VjsybPluH4MMDFbf06Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Souha-Kabtni/Food-Sales-Predictions/blob/main/Copy_of_Copy_of_Project_1_Part_4_(Core).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⛳ # The first project will be a sales prediction for food items sold at various stores.\n",
        "# **The goal of this is to help the retailer understand the properties of products and outlets that play crucial roles in increasing sales.**"
      ],
      "metadata": {
        "id": "bsi_nuN4-AhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 1:**"
      ],
      "metadata": {
        "id": "GvuGyf6rc-li"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1st: upload the file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QAwi-EcVK94U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9zUMmcKK3nH"
      },
      "outputs": [],
      "source": [
        "# 2nd: Import my to be used packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import os\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3rd: Read the fil with pandas\n",
        "df = pd.read_csv('/content/drive/MyDrive/Coding_Dojo/Week 2/Assingments/sales_predictions_2023.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "LE9TXNQYOcUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 2:**"
      ],
      "metadata": {
        "id": "0LEJKtDcc6r_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0. For me to have a general idea of my dataframe**\n",
        "\n"
      ],
      "metadata": {
        "id": "hHDSFiqf9X4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "QACk5gqrOzYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. How many rows and columns?**\n",
        "\n"
      ],
      "metadata": {
        "id": "mNsBtBe279KA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'columns : {df.shape[1]}') # The code is asked to print the sentence columns :the number of columns\n",
        "print(f'rows : {df.shape[0]}')    # The code is asked to print the sentence rows :the number of rows"
      ],
      "metadata": {
        "id": "iXnneFV374Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What are the datatypes of each variable?**"
      ],
      "metadata": {
        "id": "7hSOcFZ58K2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "GHl7JE2C8E0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Are there duplicates? If so, drop any duplicates.**\n"
      ],
      "metadata": {
        "id": "tfSu7cKR8SuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()\n",
        "# Ths output of the .duplicated().sum() gave 0 ==> We have no duplicated rows to drop in the 1st place"
      ],
      "metadata": {
        "id": "vgdQqOt08OJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OR displaying the data frame\n",
        "df[df.duplicated(keep=False)]"
      ],
      "metadata": {
        "id": "V18RwsRV8DXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Identify missing values.**"
      ],
      "metadata": {
        "id": "av6zm9On9S00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()\n",
        "# The output gave 2 columns with missing values"
      ],
      "metadata": {
        "id": "RV1roca19V95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Decide on how to address the missing values and do it! (This requires your judgement, so explain your choice).**"
      ],
      "metadata": {
        "id": "_kfOBiwD-TxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 2 columns with missing values that need to be treated:\n",
        "\n",
        "❎ 'Item_Weight' column's missing values will be imputed with the mean of its values (as recommended by the literature)\n",
        "\n",
        "❎ 'Outlet_Size' column's missing values will be imputed with the mode of its values (as recommended by the literature)"
      ],
      "metadata": {
        "id": "E_lM2ytn9uLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is our 1st missing values in the 'Item_Weight' column\n",
        "\n",
        "df['Item_Weight'].fillna(value =df['Item_Weight'].mean(),inplace=True )\n",
        "df.head()"
      ],
      "metadata": {
        "id": "hqhfhb_0NI0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now all missing values in 'Item_Weight' column are imputed with the mean of its values\n",
        "\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "wOPRT84_9Suk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking for the mode in Outlet_Size's unique values\n",
        "\n",
        "df['Outlet_Size'].value_counts()"
      ],
      "metadata": {
        "id": "rSSIkBrZww2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Medium is more reccurent that the other values, NaN will be replaced by it accordingly\n",
        "\n",
        "df['Outlet_Size'].fillna(value ='Medium',inplace=True )  # or df['Outlet_Size'].fillna(value =df['Outlet_Size'].mode(),inplace=True )\n",
        "df.head()"
      ],
      "metadata": {
        "id": "-m9xF9Dn9hXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "tBOc52PC-35L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**✅ Now our data is free from Missing values**"
      ],
      "metadata": {
        "id": "n37K9pE1-7cM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Confirm that there are no missing values after addressing them.**"
      ],
      "metadata": {
        "id": "DDaBGqV2_8WQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()\n",
        "# As per the .isna().sum() diplayed above, all values are cleared from (null) values."
      ],
      "metadata": {
        "id": "zZCOA3YsM8a1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Find and fix any inconsistent categories of data (example: fix cat, Cat, and cats so that they are consistent)**\n",
        "\n"
      ],
      "metadata": {
        "id": "Ku3_4GDgBGLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Locate my Object columns\n",
        "df_types = df.dtypes\n",
        "df_types"
      ],
      "metadata": {
        "id": "X_0OwpiD56C_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract my Object columns only\n",
        "str_cols = df_types[df_types==\"O\"]\n",
        "str_cols"
      ],
      "metadata": {
        "id": "BzwUF8jv5vis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the index of each\n",
        "str_cols.index"
      ],
      "metadata": {
        "id": "J8Qcog8K6qX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[str_cols.index].head()"
      ],
      "metadata": {
        "id": "J5US6lEm6ylj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str_cols = str_cols.index"
      ],
      "metadata": {
        "id": "vJ-TK9tP6581"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str_cols"
      ],
      "metadata": {
        "id": "eSUEnjlp68dR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in str_cols:\n",
        "  print(f\"{col}:\")\n",
        "  print(df[col].value_counts(dropna=False))\n",
        "  print(\"\\n\\n\")\n"
      ],
      "metadata": {
        "id": "nDXTv7gw473g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**❎ Found that Item_Fat_Content column contains both**\n",
        "\n",
        "1. 'Low Fat' and 'LF', which seems to be the same, yet written differently YET read as different values by the program\n",
        "2. 'Regula' and 'reg', which seems to be the same, yet written differently YET read as different values by the program\n",
        "\n",
        "=> Replacinng both Low Fat and 'LF' by 'Low_Fat' and 'reg' by 'Regular'\n"
      ],
      "metadata": {
        "id": "346lr_c_HNos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Item_Fat_Content'] = df['Item_Fat_Content'].str.replace('LF',\"Low Fat\")\n",
        "df['Item_Fat_Content'].value_counts()"
      ],
      "metadata": {
        "id": "wLOfq9e7G3YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Item_Fat_Content'] = df['Item_Fat_Content'].str.replace('low fat',\"Low Fat\")\n",
        "df['Item_Fat_Content'].value_counts()"
      ],
      "metadata": {
        "id": "eOSVCu4xIgJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Item_Fat_Content'] = df['Item_Fat_Content'].str.replace('reg',\"Regular\")\n",
        "df['Item_Fat_Content'].value_counts()"
      ],
      "metadata": {
        "id": "Gi0Cge5OIjA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OR in just ONE line\n",
        "# df.replace({'LF': 'Low Fat', 'low fat': 'Low Fat', 'reg':'Regular'},inplace=True)"
      ],
      "metadata": {
        "id": "-xjPi9KoASfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. For any numerical columns, obtain the summary statistics of each (min, max, mean)**"
      ],
      "metadata": {
        "id": "SXk71X_SBQbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the summary of my data\n",
        "df_summary = df.describe()\n",
        "df_summary"
      ],
      "metadata": {
        "id": "aEYM97ozBVnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OR\n",
        "# numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "# num_df = df.select_dtypes(include=numerics)\n",
        "# num_df.describe()"
      ],
      "metadata": {
        "id": "GY1B-fp4BsRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the min from the min dataframe, df_summary\n",
        "display(min)\n",
        "df_summary.loc['min', :].round()"
      ],
      "metadata": {
        "id": "AbwceE8XSKAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the max from the max dataframe, df_summary\n",
        "display(max)\n",
        "df_summary.loc['max', :].round()"
      ],
      "metadata": {
        "id": "Bl2uc63oVemr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the min from the mean dataframe, df_summary\n",
        "print('Mean')\n",
        "df_summary.loc['mean', :].round()"
      ],
      "metadata": {
        "id": "lMOya57AV-GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 4 (emanating from Part 3)**\n"
      ],
      "metadata": {
        "id": "9QBA7vb8s1XX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Ranking through Bar Chart\n",
        "**Regualr Bar Chart with 3 variables using groupby**"
      ],
      "metadata": {
        "id": "8go8zLk_Gib8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "kK4sYVdl71-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Item_Fat_Content     2\n",
        "Item_Type           16\n",
        "Outlet_Identifier   10\n",
        "Outlet_Size          3\n",
        "Outlet_Location_Type 3\n",
        "Outlet_Type          4"
      ],
      "metadata": {
        "id": "5TKjImsN8TH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dist1(data, xcol, ycol, hue, title, figure_size = (20, 10)):\n",
        "\n",
        "  ## Through plt.subplots(), I am going to set the ground for a larger fig/ax before plotting\n",
        "\n",
        " fig, ax = plt.subplots(figsize=figure_size)\n",
        "\n",
        "## I am going to removing my top and right borders\n",
        "\n",
        " ax.spines['right'].set_visible(False)\n",
        " ax.spines['top'].set_visible(False)\n",
        "\n",
        "## I am going to plot a histogram using seaborn library\n",
        "\n",
        " sns.barplot(data=data, x = xcol, y = ycol, hue=hue, ax=ax)\n",
        "\n",
        "## I am going to set my title and my font (family, size, and weight)\n",
        "\n",
        " ax.set_title(title, fontfamily='serif', fontsize='xx-large', fontweight='semibold');\n",
        "\n",
        "## I am going to increase my Axis Label Font Sizes\n",
        "\n",
        " ax.set_xlabel(ax.xaxis.get_label().get_text(),\n",
        "              fontsize='x-large')\n",
        " ax.set_ylabel(ax.yaxis.get_label().get_text(),\n",
        "              fontsize='x-large')\n",
        "\n",
        " plt.xticks(rotation = 45)\n",
        "\n",
        " ## ax.xaxis.label()\n",
        " ax.legend(loc='upper right');"
      ],
      "metadata": {
        "id": "k_Cbd8FILrvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dist1(df, df.Item_Type, df.Item_Weight, df.Item_Fat_Content, 'Average Item Weight by Item Type and Item Fat Content')\n",
        "plot_dist1(df, df.Item_Type, df.Item_Visibility, df.Item_Fat_Content, 'Average Item Visibility by Item Type and Item Fat Content')\n",
        "plot_dist1(df, df.Item_Type, df.Item_MRP, df.Item_Fat_Content, 'Average Item MRP by Item Type and Item Fat Content')\n",
        "plot_dist1(df, df.Item_Type, df.Item_Outlet_Sales, df.Item_Fat_Content, 'Average Item Weight by Item Type and Item Fat Content')\n",
        "\n"
      ],
      "metadata": {
        "id": "ftuzI16XP6py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **✅ Interpretation: The graph shows that the 4 items: Household, Health and Hygiene, Hard Drinks and Chers have no Regular fat, they are rather purely Low Fat. Additionally, Seafood and Breakfast are Regular and Low Fat, respectively**"
      ],
      "metadata": {
        "id": "gb0Etnr3ZYa_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Studying the Distribution of my Numerical columns through Histograms**"
      ],
      "metadata": {
        "id": "9DlLwVfdhh_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since I have 5 Numerical columns, and to avoid repetition of codes, I will create a function for a histogram and call it plot_dist\n",
        "\n",
        "def plot_dist(data, col, title, figure_size = (10,5)):  # def plot_dist(data, col, title, figure_size = (10,5), font_family = 'serif', font_weight = 'semibold') => Why they did not work?\n",
        "\n",
        "## Through plt.subplots(), I am going to set the ground for a larger fig/ax before plotting\n",
        "\n",
        " fig, ax = plt.subplots(figsize=figure_size)\n",
        "\n",
        "## I am going to removing my top and right borders\n",
        "\n",
        " ax.spines['right'].set_visible(False)\n",
        " ax.spines['top'].set_visible(False)\n",
        "\n",
        "## I am going to plot a histogram using seaborn library\n",
        "\n",
        " sns.histplot(data=data, x=col, ax=ax)\n",
        "\n",
        "## I am going to set my title and my font (family, size, and weight)\n",
        "\n",
        " ax.set_title(title, fontfamily='serif', fontsize='xx-large', fontweight='semibold');\n",
        "\n",
        "## I am going to increase my Axis Label Font Sizes\n",
        "\n",
        " ax.set_xlabel(ax.xaxis.get_label().get_text(),\n",
        "              fontsize='x-large')\n",
        " ax.set_ylabel(ax.yaxis.get_label().get_text(),\n",
        "              fontsize='x-large')\n",
        "\n",
        "## I am going to make sales_format using the StrMethodFormatter and the format code that will display the Number format with comma separator with no decimal places (info taken from https://mkaz.blog/working-with-python/string-formatting/)\n",
        "\n",
        " sales_format = mpl.ticker.StrMethodFormatter('${x:,.0f}')\n",
        " ax.xaxis.set_major_formatter(sales_format)\n",
        "\n",
        "## Annotating mean\n",
        "\n",
        " mean = data[col].mean()\n",
        " ax.axvline(mean,color='k', ls='solid', lw=3,\n",
        "           label= f\"Mean= ${mean:,.2f}\");\n",
        "\n",
        "## Annotating median\n",
        "\n",
        " median = data[col].median()\n",
        " ax.axvline(median,color='r', ls=':', lw=3,\n",
        "           label= f\"Median= ${median:,.2f}\");\n",
        "\n",
        "## ax.xaxis.label()\n",
        " ax.legend(loc='upper right');\n"
      ],
      "metadata": {
        "id": "FsAgMEDrhiVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dist(df, 'Item_Weight', 'Distribution of Item Weights');\n",
        "plot_dist(df, 'Item_Visibility', 'Distribution of Item Visibility');\n",
        "plot_dist(df, 'Item_MRP', 'Distribution of Item MRP');\n",
        "plot_dist(df, 'Outlet_Establishment_Year', 'Distribution of Outlet Establishment Year');\n",
        "plot_dist(df, 'Item_Outlet_Sales', 'Distribution of Item Outlet Sales');"
      ],
      "metadata": {
        "id": "EETMPVxshmQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Correlation - Chart Type: Heatmap"
      ],
      "metadata": {
        "id": "H-inBlVpHD3q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **❎ Justifying my decision of using a Heatmap: I judge that the best way to visualize correlation between the features of my dataframe is by using a heatmap.**"
      ],
      "metadata": {
        "id": "bMqwlcid6Y_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I am searching for the correlation between all numercial values in my df dataframe\n",
        "correlation = df.corr()\n",
        "correlation"
      ],
      "metadata": {
        "id": "VqQG9mknt6mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.heatmap(df.corr(),cmap='plasma', annot=True);"
      ],
      "metadata": {
        "id": "AYGud_nu2_Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✅ Interpretation: I will focus my attention on Item_Outlet_Sales and link the other 3 elements to it as I interpret the results, since it is the ultimate target variable to be predicted. the As per the heatmap results:\n",
        "\n",
        "# **+ With a positive correlation of 0.57, Item_MRP and Item_Outlet_Sales moderately correlate.**\n",
        "# **+ With a negative correlation of -0.13 and -0.049 between Item_Visibility and Outlet_Establishment_Year respectively with Item_Outlet_Sales.**\n",
        "\n",
        "# **==> Conclusion: The more the product is high in price, the more it is sold.**"
      ],
      "metadata": {
        "id": "zWVMzGGCzeGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Studying the Distribution through Boxplots"
      ],
      "metadata": {
        "id": "QQNJfAbPD_Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Outlet_Identifier   10 NO!\n",
        "Outlet_Size          3\n",
        "Outlet_Location_Type 3\n",
        "Outlet_Type          4"
      ],
      "metadata": {
        "id": "U_7OyMnurQrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dist3(data, xcol, ycol, hue, title, figure_size = (20, 10)):\n",
        "\n",
        "  ## Through plt.subplots(), I am going to set the ground for a larger fig/ax before plotting\n",
        "\n",
        " fig, ax = plt.subplots(figsize=figure_size)\n",
        "\n",
        "## I am going to removing my top and right borders\n",
        "\n",
        " ax.spines['right'].set_visible(False)\n",
        " ax.spines['top'].set_visible(False)\n",
        "\n",
        "## I am going to plot a histogram using seaborn library\n",
        "\n",
        " sns.boxplot(data=data, x = xcol, y = ycol, hue=hue, ax=ax)\n",
        "\n",
        "## I am going to set my title and my font (family, size, and weight)\n",
        "\n",
        " ax.set_title(title, fontfamily='serif', fontsize='xx-large', fontweight='semibold');\n",
        "\n",
        "## I am going to increase my Axis Label Font Sizes\n",
        "\n",
        " ax.set_xlabel(ax.xaxis.get_label().get_text(),\n",
        "              fontsize='x-large')\n",
        " ax.set_ylabel(ax.yaxis.get_label().get_text(),\n",
        "              fontsize='x-large')\n",
        "\n",
        " plt.xticks(rotation = 0)\n",
        "\n",
        " ## ax.xaxis.label()\n",
        " ax.legend(loc='upper right');"
      ],
      "metadata": {
        "id": "7dkLbugm7wJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dist3(df, df.Outlet_Type, df.Item_Outlet_Sales, df.Outlet_Location_Type, '??????????')\n",
        "plot_dist3(df, df.Outlet_Type, df.Item_Outlet_Sales, df.Outlet_Size , '??????????')\n"
      ],
      "metadata": {
        "id": "Q0GoPTgVo60i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=df, x='Item_Fat_Content', y='Item_Weight')"
      ],
      "metadata": {
        "id": "EdQudhQ2EdDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=df, x='Outlet_Size', y='Item_Weight')"
      ],
      "metadata": {
        "id": "Q0NHCxTBEjJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART 4:**"
      ],
      "metadata": {
        "id": "HXOjOMS3d7we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Through plt.subplots(), I am going to set the ground for a larger fig/ax before plotting\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "\n",
        "## I am going to plot a histogram using seaborn library\n",
        "\n",
        "sns.histplot(data=df, x='Item_Outlet_Sales', ax=ax)\n",
        "ax.set(title='Distribution of the Sales of products');\n",
        "\n",
        "## I am going to make sales_format using the StrMethodFormatter and the format code that will display the Number format with comma separator with no decimal places (info taken from https://mkaz.blog/working-with-python/string-formatting/)\n",
        "sales_format = mpl.ticker.StrMethodFormatter('${x:,.0f}')\n",
        "ax.xaxis.set_major_formatter(sales_format)\n",
        "\n",
        "## Annotating mean\n",
        "mean_sales = df['Item_Outlet_Sales'].mean()\n",
        "ax.axvline(mean_sales,color='r', ls=':', lw=3,\n",
        "           label= f\"Mean= ${mean_sales:,.2f}\");\n",
        "\n",
        "## Annotating median\n",
        "median_sales = df['Item_Outlet_Sales'].median()\n",
        "ax.axvline(median_sales,color='k', ls=':', lw=3,\n",
        "           label= f\"Median= ${median_sales:,.2f}\");\n",
        "\n",
        "ax.legend();\n",
        "\n",
        "\n",
        "plt.rcParams.update( {'font.family':'monospace',\n",
        "                      'figure.figsize':(10,10),\n",
        "             'font.weight':'light'})"
      ],
      "metadata": {
        "id": "rSlF7125xvLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## I am going the calculate the mean rating for Item MRP when grouped by both Item Type and Item Fat Content\n",
        "\n",
        "df_grouped = df.groupby(['Item_Type', 'Item_Fat_Content'])['Item_MRP'].mean().reset_index()\n",
        "df_grouped.head()"
      ],
      "metadata": {
        "id": "uqUcsFnmm92S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}